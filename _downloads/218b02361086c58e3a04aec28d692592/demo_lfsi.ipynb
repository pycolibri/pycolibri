{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Demo Filtered Spectral Initialization\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Select Working Directory and Device\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os\n\nfrom torch.utils import data\n\nos.chdir(os.path.dirname(os.getcwd()))\nprint(\"Current Working Directory \", os.getcwd())\n\nimport sys\n\nsys.path.append(os.path.join(os.getcwd()))\n\n# General imports\nimport matplotlib.pyplot as plt\nimport torch\nimport os\n\n# Set random seed for reproducibility\ntorch.manual_seed(0)\n\nmanual_device = \"cpu\"\n# Check GPU support\nprint(\"GPU support: \", torch.cuda.is_available())\n\nif manual_device:\n    device = manual_device\nelse:\n    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load dataset\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from colibri.data.datasets import CustomDataset\nimport torchvision\nname = \"cifar10\"\npath = \".\"\nbatch_size = 1\n\n\ndataset = CustomDataset(name, path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualize dataset\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from torchvision.utils import make_grid\n\nsample = dataset[0][\"input\"]\nsample = sample.mean(0)\nsample = sample.unsqueeze(0).to(device)\nsample = torchvision.transforms.Resize((128, 128))(sample)\nsample = 1*(sample - torch.min(sample)) / (torch.max(sample) - torch.min(sample))\nsample = torch.exp(1j * 2*torch.pi * sample)\nsample = torch.nn.functional.pad(sample, (32, 32, 32, 32), mode='constant', value=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Optics forward model\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from colibri.optics import CodedPhaseImaging\nfrom colibri.optics.functional import coded_phase_imaging_forward, coded_phase_imaging_backward\n\n\nimg_size = sample.shape[1:]\n\n\n\nwave_length = 670e-9\npixel_size = 1e-6\nsensor_distance = 50e-6\napproximation = \"fresnel\"\n\n\n\nacquisition_model = CodedPhaseImaging(\n    input_shape=img_size,\n    pixel_size=pixel_size,\n    wavelength=wave_length,\n    sensor_distance=sensor_distance,\n    approximation=approximation,\n    trainable=False,\n)\n\n\ny = acquisition_model(sample, type_calculation=\"forward\", intensity=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Estimate phase \n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from colibri.recovery import LFSI\n\n\nlfsi_algorithm = LFSI(\n                    max_iters=15,\n                    p=0.9,\n                    k_size=5,\n                    sigma=1.0,\n                    train_filter=False,\n                    dtype=torch.float32,\n                    device=device,\n)\n\nx_hat = lfsi_algorithm(y, acquisition_model)\n\n\nsample = sample.detach().cpu().squeeze().angle()\ny = y.detach().cpu().squeeze()\nx_hat = x_hat.detach().cpu().squeeze().angle()\n\nnormalize = lambda x: (x - torch.min(x)) / (torch.max(x) - torch.min(x))\n\nfig, axs = plt.subplots(1, 3, figsize=(15, 5))\n\naxs[0].set_title(\"Reference\")\naxs[0].imshow(sample, cmap=\"gray\")\naxs[0].set_xticks([])\naxs[0].set_yticks([])\n\naxs[1].set_title(\"Measurement\")\naxs[1].imshow(y, cmap=\"gray\")\naxs[1].set_xticks([])\naxs[1].set_yticks([])\n\naxs[2].set_title(\"Estimation\")\naxs[2].imshow(x_hat, cmap=\"gray\")\naxs[2].set_xticks([])\naxs[2].set_yticks([])\n\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.22"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}