{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Demo DOEs.\n\nIn this example we show how to use a DOE,\n\nIn progress...\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Select Working Directory and Device\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os\n\nfrom torch.utils.data import DataLoader\n\nos.chdir(os.path.dirname(os.getcwd()))\nprint(\"Current Working Directory \", os.getcwd())\n\nimport numpy as np\nfrom colibri.optics.functional import (\n    psf_single_doe_spectral,\n    convolutional_sensing,\n    ideal_panchromatic_sensor,\n)\nfrom colibri.optics.sota_does import (\n    spiral_doe,\n    conventional_lens,\n    spiral_refractive_index,\n    nbk7_refractive_index,\n)\nfrom colibri.optics import SingleDOESpectral\nfrom colibri import seed_everything\n\n# General imports\nimport matplotlib.pyplot as plt\nimport torch\nimport os\n\nseed_everything()\nmanual_device = \"cpu\"\ndoe_size = (100, 100)\nimg_size = (200, 200)\ntype_doe = \"spiral\"  # spiral, conventional_lens\nconvolution_domain = \"fourier\"  # signal, fourier\ntype_wave_propagation = \"angular_spectrum\"  # fresnel, angular_spectrum, fraunhofer\nwavelengths = torch.Tensor([450, 550, 650]) * 1e-9\n\n# Check GPU support\nprint(\"GPU support: \", torch.cuda.is_available())\n\nif manual_device:\n    device = manual_device\nelse:\n    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load dataset\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from colibri.data.datasets import CustomDataset\n\nname = \"cifar10\"\npath = \".\"\nbatch_size = 16\n\n\n\ndataset = CustomDataset(name, path)\ndataset_loader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualize dataset\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from torchvision.utils import make_grid\nimport torchvision\n\nsample = next(iter(dataset_loader))[\"input\"]\nimg = make_grid(sample[:32], nrow=8, padding=1, normalize=True, scale_each=False, pad_value=0)\n\nplt.figure(figsize=(10, 10))\nplt.imshow(img.permute(1, 2, 0))\nplt.title(\"CIFAR10 dataset\")\nplt.axis(\"off\")\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Optics forward model\nDefine the forward operators $\\mathbf{y} = \\mathbf{H}_\\phi \\mathbf{x}$, in this case, the CASSI and SPC forward models.\nEach optics model can comptute the forward and backward operators i.e., $\\mathbf{y} = \\mathbf{H}_\\phi \\mathbf{x}$ and $\\mathbf{x} = \\mathbf{H}^T_\\phi \\mathbf{y}$.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# source_distance = np.inf\nif type_wave_propagation == \"fraunhofer\":\n    source_distance = np.inf\nelse:\n    source_distance = 1  # meters\n\nif type_doe == \"spiral\":\n    radius_doe = 0.5e-3\n    sensor_distance = 50e-3\n    pixel_size = (2 * radius_doe) / np.min(doe_size)\n    height_map, aperture = spiral_doe(\n        M=doe_size[0],\n        N=doe_size[1],\n        number_spirals=3,\n        radius=radius_doe,\n        focal=50e-3,\n        start_w=450e-9,\n        end_w=650e-9,\n    )\n    refractive_index = spiral_refractive_index\n\nelse:\n    radius_doe = 0.5e-3  # .0e-3\n    focal = 50e-3\n\n    if source_distance == np.inf:\n        sensor_distance = focal  # 0.88\n    else:\n        sensor_distance = 1 / (1 / (focal) - 1 / (source_distance))\n    pixel_size = (2 * radius_doe) / np.min(doe_size)\n    height_map, aperture = conventional_lens(\n        M=doe_size[0], N=doe_size[1], focal=focal, radius=radius_doe\n    )\n    refractive_index = nbk7_refractive_index\n\nfig, ax = plt.subplots(1, 2, figsize=(10, 10))\nax[0].imshow(height_map, cmap=\"viridis\")\nax[0].set_title(\"Height map\")\nax[1].imshow(aperture, cmap=\"plasma\")\nax[1].set_title(\"Aperture map\")\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Functional API for DOEs\nDefine the recovery model $\\mathbf{x} = \\mathcal{G}_\\theta( \\mathbf{y})$, in this case, a simple U-Net model.\nYou can add you custom model by using the :meth: `build_network` function.\nAdditionally we define the end-to-end model that combines the forward and recovery models.\nDefine the loss function $\\mathcal{L}$, and the regularizers $\\mathcal{R}$ for the forward and recovery models.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "psf = psf_single_doe_spectral(\n    height_map=height_map,\n    aperture=aperture,\n    refractive_index=refractive_index,\n    wavelengths=wavelengths,\n    source_distance=source_distance,\n    sensor_distance=sensor_distance,\n    pixel_size=pixel_size,\n    approximation=type_wave_propagation,\n)\n\nfig, ax = plt.subplots(1, 1, figsize=(10, 10))\nax.imshow(((psf - psf.min()) / (psf.max() - psf.min())).permute(1, 2, 0), cmap=\"plasma\")\n\nimage = convolutional_sensing(sample, psf, domain=convolution_domain)\n\nimg = make_grid(image, nrow=4, padding=1, normalize=True, scale_each=False, pad_value=0)\n\nplt.figure(figsize=(10, 10))\nplt.imshow(img.permute(1, 2, 0))\nplt.title(\"CIFAR10 imaged\")\nplt.axis(\"off\")\nplt.show()\n\nimage = ideal_panchromatic_sensor(image)\n\nimg = make_grid(image, nrow=4, padding=1, normalize=True, scale_each=False, pad_value=0)\n\nplt.figure(figsize=(10, 10))\nplt.imshow(img.permute(1, 2, 0))\nplt.title(\"CIFAR10 imaged pancromatic sensor\")\nplt.axis(\"off\")\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## DOE Class\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "acquisition_model = SingleDOESpectral(\n    input_shape=sample.shape[1:],\n    height_map=height_map,\n    aperture=aperture,\n    wavelengths=wavelengths,\n    source_distance=source_distance,\n    sensor_distance=sensor_distance,\n    sensor_spectral_sensitivity=lambda x: x,\n    pixel_size=pixel_size,\n    doe_refractive_index=refractive_index,\n    approximation=type_wave_propagation,\n    domain=convolution_domain,\n    trainable=False,\n)\n\npsf = acquisition_model.get_psf()\nfig, ax = plt.subplots(1, 1, figsize=(10, 10))\nax.imshow(((psf - psf.min()) / (psf.max() - psf.min())).permute(1, 2, 0), cmap=\"plasma\")\nax.set_title(\"RGB PSF\")\nplt.show()\n\nimage = acquisition_model(sample)\n\nimg = make_grid(image, nrow=4, padding=1, normalize=True, scale_each=False, pad_value=0)\n\nplt.figure(figsize=(10, 10))\nplt.imshow(img.permute(1, 2, 0))\nplt.title(\"CIFAR10 imaged\")\nplt.axis(\"off\")\nplt.show()\n\nimage = ideal_panchromatic_sensor(image)\n\nimg = make_grid(image, nrow=4, padding=1, normalize=True, scale_each=False, pad_value=0)\n\nplt.figure(figsize=(10, 10))\nplt.imshow(img.permute(1, 2, 0))\nplt.title(\"CIFAR10 imaged pancromatic sensor\")\nplt.axis(\"off\")\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.22"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}