{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Demo Colibri.\n\nIn this example we show how to use a simple pipeline of end-to-end learning with the CASSI and SPC forward models. Mainly, the forward model is defined,\n\n\\begin{align}\\mathbf{y} = \\mathbf{H}_\\phi \\mathbf{x}\\end{align}\n\nwhere $\\mathbf{H}$ is the forward model, $\\mathbf{x}$ is the input image and $\\mathbf{y}$ is the measurement and $\\phi$ are the coding elements of the forward model. The recovery model is defined as,\n\n\\begin{align}\\mathbf{x} = \\mathcal{G}_\\theta( \\mathbf{y})\\end{align}\n\nwhere $\\mathcal{G}$ is the recovery model and $\\theta$ are the parameters of the recovery model.\n\nThe training is performed by minimizing the following loss function,\n\n\\begin{align}\\{\\phi^*,\\theta^*\\} = \\arg \\min_{\\phi,\\theta} \\sum_{p=1}^{P}\\mathcal{L}(\\mathbf{x}_p, \\mathcal{G}_\\theta( \\mathbf{H}_\\phi \\mathbf{x}_p)) + \\lambda \\mathcal{R}(\\phi) + \\mu \\mathcal{R}(\\mathbf{H}_\\phi \\mathbf{x})\\end{align}\n\nwhere $\\mathcal{L}$ is the loss function, $\\mathcal{R}$ is the regularizer, $\\lambda$ and $\\mu$ are the regularization weights, and $P$ is the number of samples in the training dataset.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Select Working Directory and Device\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os\n\nos.chdir(os.path.dirname(os.getcwd()))\nprint(\"Current Working Directory \", os.getcwd())\n\n# General imports\nimport matplotlib.pyplot as plt\nimport torch\nfrom torch.utils.data import DataLoader\n\nmanual_device = \"cpu\"\n# Check GPU support\nprint(\"GPU support: \", torch.cuda.is_available())\n\nif manual_device:\n    device = manual_device\nelse:\n    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load dataset\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from colibri.data.datasets import CustomDataset\n\nname = 'cifar10'  # ['cifar10', 'cifar100', 'mnist', 'fashion_mnist', 'cave']\npath = '.'\nbatch_size = 128\nacquisition_name = 'c_cassi'  # ['spc', 'cassi', 'doe']\n\n\ndataset = CustomDataset(name, path)\n\n\ndataset_loader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualize dataset\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from torchvision.utils import make_grid\n\nsample = next(iter(dataset_loader))['input']\nimg = make_grid(sample[:32], nrow=8, padding=1, normalize=True, scale_each=False, pad_value=0)\n\nplt.figure(figsize=(10, 10))\nplt.imshow(img.permute(1, 2, 0))\nplt.title('CIFAR10 dataset')\nplt.axis('off')\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Optics forward model\nDefine the forward operators $\\mathbf{y} = \\mathbf{H}_\\phi \\mathbf{x}$, in this case, the CASSI and SPC forward models.  \nEach optics model can comptute the forward and backward operators i.e., $\\mathbf{y} = \\mathbf{H}_\\phi \\mathbf{x}$ and $\\mathbf{x} = \\mathbf{H}^T_\\phi \\mathbf{y}$.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import math\nfrom colibri.optics import SPC, SD_CASSI, DD_CASSI, C_CASSI, SingleDOESpectral\nfrom colibri.optics.sota_does import spiral_doe, spiral_refractive_index\n\nimg_size = sample.shape[1:]\n\nacquisition_config = dict(\n    input_shape=img_size,\n)\n\nif acquisition_name == 'spc':\n    n_measurements  = 256 \n    n_measurements_sqrt = int(math.sqrt(n_measurements))    \n    acquisition_config['n_measurements'] = n_measurements\n\nelif acquisition_name == 'doe':\n    wavelengths = torch.Tensor([450, 550, 650])*1e-9\n    doe_size = [100, 100]\n    radius_doe = 0.5e-3\n    source_distance = 1  # meters\n    sensor_distance = 50e-3\n    pixel_size = (2 * radius_doe) / min(doe_size)\n    height_map, aperture = spiral_doe(M=doe_size[0], N=doe_size[1],\n                                      number_spirals=3, radius=radius_doe,\n                                      focal=50e-3, start_w=450e-9, end_w=650e-9)\n    refractive_index = spiral_refractive_index\n\n    acquisition_config.update({\"height_map\": height_map,\n                               \"aperture\": aperture,\n                               \"wavelengths\": wavelengths,\n                               \"source_distance\": source_distance,\n                               \"sensor_distance\": sensor_distance,\n                               \"sensor_spectral_sensitivity\": lambda x: x,\n                               \"pixel_size\": pixel_size,\n                               \"doe_refractive_index\": refractive_index,\n                               \"trainable\": True})\n\nacquisition_model = {\n    'spc': SPC,\n    'sd_cassi': SD_CASSI,\n    'dd_cassi': DD_CASSI,\n    'c_cassi': C_CASSI,\n    'doe': SingleDOESpectral,\n}[acquisition_name]\n\nacquisition_model = acquisition_model(**acquisition_config)\n\ny = acquisition_model(sample)\n\nif acquisition_name == 'spc':\n    y = y.reshape(y.shape[0], -1, n_measurements_sqrt, n_measurements_sqrt)\n\nimg = make_grid(y[:32], nrow=8, padding=1, normalize=True, scale_each=False, pad_value=0)\n\nplt.figure(figsize=(10, 10))\nplt.imshow(img.permute(1, 2, 0))\nplt.axis('off')\nplt.title(f'{acquisition_name.upper()} measurements')\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Reconstruction model\nDefine the recovery model $\\mathbf{x} = \\mathcal{G}_\\theta( \\mathbf{y})$, in this case, a simple U-Net model. \nYou can add you custom model by using the :meth: `build_network` function.\nAdditionally we define the end-to-end model that combines the forward and recovery models.\nDefine the loss function $\\mathcal{L}$, and the regularizers $\\mathcal{R}$ for the forward and recovery models. \n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from colibri.models import build_network, Unet, Autoencoder\nfrom colibri.misc import E2E\nfrom colibri.train import Training\nfrom colibri.metrics import psnr, ssim\n\nfrom colibri.regularizers import (\n    Binary,\n    Transmittance,\n    MinVariance,\n    KLGaussian,\n)\n\nnetwork_config = dict(\n    in_channels=sample.shape[1],\n    out_channels=sample.shape[1],\n    reduce_spatial=True  # Only for Autoencoder\n)\n\nrecovery_model = build_network(Unet, **network_config)\n\nmodel = E2E(acquisition_model, recovery_model)\nmodel = model.to(device)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\nlosses = {\"MSE\": torch.nn.MSELoss(), \"L1\": torch.nn.L1Loss()}\nmetrics = {\"PSNR\": psnr, \"SSIM\": ssim}\nlosses_weights = [1.0, 1.0]\n\nn_epochs = 10\nsteps_per_epoch = 10\nfrequency = 1\n\nif \"cassi\" in acquisition_name or \"spc\" in acquisition_name:\n    regularizers_optics_ce = {\"RB\": Binary(), \"RT\": Transmittance()}\n    regularizers_optics_ce_weights = [50, 1]\nelse:\n    regularizers_optics_ce = {}\n    regularizers_optics_ce_weights = []\n\nregularizers_optics_mo = {\"MV\": MinVariance(), \"KLG\": KLGaussian(stddev=0.1)}\nregularizers_optics_mo_weights = [1e-3, 0.1]\n\ntrain_schedule = Training(\n    model=model,\n    train_loader=dataset_loader,\n    optimizer=optimizer,\n    loss_func=losses,\n    losses_weights=losses_weights,\n    metrics=metrics,\n    regularizers=None,\n    regularization_weights=None,\n    schedulers=[],\n    callbacks=[],\n    device=device,\n    regularizers_optics_ce=regularizers_optics_ce,\n    regularization_optics_weights_ce=regularizers_optics_ce_weights,\n    regularizers_optics_mo=regularizers_optics_mo,\n    regularization_optics_weights_mo=regularizers_optics_mo_weights,\n)\n\nresults = train_schedule.fit(\n    n_epochs=n_epochs, steps_per_epoch=steps_per_epoch, freq=frequency\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualize results\nPerforms the inference $\\tilde{\\mathbf{x}} = \\mathcal{G}_{\\theta^*}( \\mathbf{H}_{\\phi^*}\\mathbf{x})$ and visualize the results.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "x_est = model(sample.to(device)).cpu()\ny = acquisition_model(sample.to(device)).cpu()\n\nnormalize = lambda x: (x - torch.min(x)) / (torch.max(x) - torch.min(x)) \n\nif acquisition_name == 'spc':\n    y = y.reshape(y.shape[0], -1, n_measurements_sqrt, n_measurements_sqrt)\n\nimg = make_grid(sample[:16], nrow=4, padding=1, normalize=True, scale_each=False, pad_value=0)\nimg_est = make_grid(x_est[:16], nrow=4, padding=1, normalize=True, scale_each=False, pad_value=0)\nimg_y = make_grid(y[:16], nrow=4, padding=1, normalize=True, scale_each=False, pad_value=0)\n\nimgs_dict = {\n    \"CIFAR10 dataset\": img, \n    f\"{acquisition_name.upper()} measurements\": img_y,\n    \"Recons CIFAR10\": img_est\n}\n\nplt.figure(figsize=(14, 2.7))\n\nfor i, (title, img) in enumerate(imgs_dict.items()):\n    plt.subplot(1, 4, i + 1)\n    plt.imshow(img.permute(1, 2, 0))\n    plt.title(title)\n    plt.axis('off')\n\nca = normalize(acquisition_model.learnable_optics.cpu().detach())\nca = ca.numpy().squeeze()\n\nif acquisition_name == 'spc':\n    ca = ca = ca.reshape(n_measurements, 32, 32, 1)[0]\nelif acquisition_name == 'c_cassi':\n    ca = ca.transpose(1, 2, 0)\nplt.subplot(1, 4, 4)\nplt.imshow(ca, cmap='gray')\nplt.axis('off')\nplt.title('Learned CA')\nplt.colorbar()\n\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.22"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}